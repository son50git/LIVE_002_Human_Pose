{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PKT_001_Rework_03.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPUnLqBh/j4nrW90Glrmhr8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/son50git/LIVE_002_Human_Pose/blob/master/PKT_001_Rework_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbc1rESWPtCg"
      },
      "source": [
        "from __future__ import print_function  \n",
        "# for Python2 compatibility"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTi1SQSSP7kS"
      },
      "source": [
        "import numpy \n",
        "numpy.random.seed(1337)   # for experiment reproducibility"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw-6Kl9IP-6i"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense \n",
        "from keras.optimizers import SGD \n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv71aRcVQBip"
      },
      "source": [
        "num_classes = 10\n",
        "batch_size = 128     \n",
        "epochs = 20"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZmXki9gQJCI"
      },
      "source": [
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDtsFDUSQPpa",
        "outputId": "4a1fccd2-d58b-4752-fa63-089fefbc38b7"
      },
      "source": [
        "print(type(x_train))\n",
        "print(x_train.shape)\n",
        "print(type(y_train))\n",
        "print(y_train.shape)\n",
        "\n",
        "print(type(x_test))\n",
        "print(x_test.shape)\n",
        "print(type(y_test))\n",
        "print(y_test.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(60000, 28, 28)\n",
            "<class 'numpy.ndarray'>\n",
            "(60000,)\n",
            "<class 'numpy.ndarray'>\n",
            "(10000, 28, 28)\n",
            "<class 'numpy.ndarray'>\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMPs9SCeQ1VA",
        "outputId": "81d4537c-e452-41a4-b17a-4e52be9033a2"
      },
      "source": [
        "x_train[0:3]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUO7ITIlQ8U6",
        "outputId": "0fa38745-d3a7-4d34-f5cf-c3e56ed464e5"
      },
      "source": [
        "x_train = x_train.reshape(60000, 784)  # 28x28 = 784\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "\n",
        "x_train = x_train.astype('float32') \n",
        "x_test = x_test.astype('float32') \n",
        "\n",
        "x_train /= 255  # 0 - 255 ...  0-1 \n",
        "x_test /= 255   # normalizing your data \n",
        "\n",
        "print(x_train[0])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
            " 0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
            " 0.96862745 0.49803922 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
            " 0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.19215687\n",
            " 0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
            " 0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
            " 0.96862745 0.94509804 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
            " 0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.04313726\n",
            " 0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.13725491 0.94509804\n",
            " 0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
            " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
            " 0.5882353  0.10588235 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
            " 0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.15294118 0.5803922\n",
            " 0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.07058824 0.67058825\n",
            " 0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
            " 0.3137255  0.03529412 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.53333336 0.99215686\n",
            " 0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXF9RPk8Ra0O",
        "outputId": "75e2eca3-bd90-4bff-d126-b92598a0e13d"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwYEsnICRgJH",
        "outputId": "090036cb-a244-45a7-e964-d251aa1df4d3"
      },
      "source": [
        "print(y_train[0])\n",
        "y_train[0:10]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwvJh4kYRsaK"
      },
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train2 = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test2 = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY54zDiWRzpv",
        "outputId": "c931cb87-fef3-493e-e7c8-501ff32dc7d5"
      },
      "source": [
        "y_train2[0:10] # one-hot vector"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9Bvm-gWYk88"
      },
      "source": [
        "y_train = y_train2\n",
        "y_test = y_test2"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSUGZ0GjXxOE"
      },
      "source": [
        "model = Sequential()\n",
        "model.add( Dense(512, activation='sigmoid', input_shape=(784,)  ) )\n",
        "model.add( Dense(512, activation='sigmoid'  ) )\n",
        "model.add( Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljK20_KNYGP9",
        "outputId": "d5b7d0eb-b090-47e5-cc75-21a66d241649"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_rISGZIYTbn"
      },
      "source": [
        "# Compile the model \n",
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pRTsC0eYZWA",
        "outputId": "6511df61-73d9-4eec-9eca-5ae97a9c2bef"
      },
      "source": [
        "# let's perform the learning \n",
        "history = model.fit( x_train, y_train, \n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs, \n",
        "           verbose=1, \n",
        "           validation_data=(x_test, y_test))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 2.2652 - accuracy: 0.2118 - val_loss: 2.2230 - val_accuracy: 0.3242\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 2.1832 - accuracy: 0.4008 - val_loss: 2.1319 - val_accuracy: 0.5642\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 2.0751 - accuracy: 0.5360 - val_loss: 2.0006 - val_accuracy: 0.5880\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 1.9148 - accuracy: 0.6114 - val_loss: 1.8032 - val_accuracy: 0.6736\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 1.6932 - accuracy: 0.6661 - val_loss: 1.5553 - val_accuracy: 0.7049\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 1.4429 - accuracy: 0.7120 - val_loss: 1.3077 - val_accuracy: 0.7373\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 1.2193 - accuracy: 0.7497 - val_loss: 1.1073 - val_accuracy: 0.7757\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 1.0455 - accuracy: 0.7768 - val_loss: 0.9611 - val_accuracy: 0.7849\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.9163 - accuracy: 0.7941 - val_loss: 0.8485 - val_accuracy: 0.8004\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.8192 - accuracy: 0.8108 - val_loss: 0.7633 - val_accuracy: 0.8203\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.7441 - accuracy: 0.8247 - val_loss: 0.6973 - val_accuracy: 0.8287\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.6852 - accuracy: 0.8325 - val_loss: 0.6448 - val_accuracy: 0.8374\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.6378 - accuracy: 0.8411 - val_loss: 0.6019 - val_accuracy: 0.8503\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.5994 - accuracy: 0.8479 - val_loss: 0.5671 - val_accuracy: 0.8562\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.5677 - accuracy: 0.8539 - val_loss: 0.5393 - val_accuracy: 0.8587\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.5410 - accuracy: 0.8591 - val_loss: 0.5131 - val_accuracy: 0.8655\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.5185 - accuracy: 0.8640 - val_loss: 0.4950 - val_accuracy: 0.8687\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.4994 - accuracy: 0.8678 - val_loss: 0.4751 - val_accuracy: 0.8724\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.4826 - accuracy: 0.8715 - val_loss: 0.4593 - val_accuracy: 0.8765\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.4681 - accuracy: 0.8746 - val_loss: 0.4455 - val_accuracy: 0.8787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqYZgLsUY6IF",
        "outputId": "c6b0806d-5716-41da-8a75-afe535852b1a"
      },
      "source": [
        "# Let's evaluate the model \n",
        "score = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4455 - accuracy: 0.8787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCLYki_ZaZbG",
        "outputId": "7672e212-2142-4f8f-a9ab-3d848fb7635c"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.4454677104949951\n",
            "Test accuracy: 0.8787000179290771\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}